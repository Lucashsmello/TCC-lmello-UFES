
\newcommand{\NbasesV}{\textit{N}}
\newcommand{\Nbases}{123}
\newcommand{\Nml}{6}
\newcommand{\NmlT}{4}
\newcommand{\NmlA}{2}
\newcommand{\Ncb}{4}
\newcommand{\MML}{método multirrótulo}
\newcommand{\MMLs}{métodos multirrótulo}
\newcommand{\MRLM}{Método Revolucionário de Lucas Mello}
\newcommand{\MRLMa}{MRLM}

\chapter{Introdução}
\begin{verbatim}
 -Falar um pouco sobre aprendizado de máquina.
 -Falar sobre Classificação multiclasse
 -Apresentar Classificação multirrótulo e falar como é mais tenso que a multiclasse, dar exemplos etc.
 -Falar um pouco do estado da arte da Classificacao multirrotulo.
 
\end{verbatim}



\section{Motivações}
% Análises dos métodos multirrótulo trazem os seguintes benefícios:
O melhor entendimento do funcionamento dos métodos multirrótulo permite:
\begin{itemize}
 \item descobrir atributos destes que se alterados, aproveitados
 e/ou combinados podem acarretar na criação de novos métodos e/ou na melhora dos existentes.
 \item prever, com uma certa taxa de erro, seus desempenhos, o que facilita o uso mais inteligente dos métodos
 sem precisar utilizar muito esforço computacional devido a testes.
 \item reforçar ou contrariar as conclusões já estabelecidas dos métodos, uma vez que a maioria delas são 
 baseadas em testes experimentais.
\end{itemize}

\section{Objetivos}
O objetivo geral deste trabalho é analisar e comparar métodos multirrótulos distintos.
Mais formalmente, a análise deve implicar em conclusões matemáticas ou estatísticas sobre o desempenho dos métodos multirrótulo.
Objetivo geral pode ser detalhado nos seguintes objetivos específicos:
\begin{itemize}
 \item Comparação estatística e análise crítica dos métodos multirrótulos;
 \item Implementação dos métodos multirrótulos em uma biblioteca que integra técnicas de reconhecimento de padrões.
\end{itemize}


% \section{Contribuições}
\section{Estrutura do Trabalho}

\chapter{Classificação multirrótulo}

\section{Enunciado do problema}
\begin{verbatim}
ESBOÇO:
-Definição formal.
-um classificador multirrótulo mapeia do espaço de características
para um vetor de valores reais entre 0 e 1 
de tamanho igual ao número de rótulos.
-falar da complexidade do problema
-falar sobre lidar o problema como probabilidade condicional dado o rótulo e etc...
    P(l_1 | x,l_2)
\end{verbatim}



\section{Avaliação de Desempenho}
\begin{verbatim}
-Apresentar matematicamente o que pode indicar correlação entre rótulos e outras coisas
conforme o artigo: "Bayes Optimal Multilabel Classification via Probabilistic Classifier Chains".
-Falar que é diferente do multiclasse
\end{verbatim}
\subsection{Métricas}
\label{sec:metrics}
\subsubsection{Accuracy}
\subsubsection{Hamming-Loss}
\subsubsection{Subset Accuracy}
\subsubsection{Ranking Loss}
\subsection{Modelo de Avaliação}
\label{sec:modelav}

\begin{verbatim}
Falar do Holdout,Cross-validation estratificado.
Falar sobre bases separadas de treino,teste e validação.
\end{verbatim}

\chapter{Métodos Multirrótulos}
\section{Transformação do Problema}
\subsection{Relevância Binária - BR}
\ref{sec:br}
\subsection{Classifier Chain}
\subsection{Ensemble of Classifier Chain}
\subsection{Probabilistic Classifier Chain}
\subsection{LEAD}
\subsection{Dependent Binary Relevance - DBR}
\label{sec:dbr}
\subsection{MAIS MÉTODOS...}

\section{Adaptação de classificadores}
\subsection{ML-KNN}
\subsection{Rede Neural Artificial}
\subsection{C4.5 multirrótulo}
\subsection{CRankSVM}
\subsection{MAIS...}


\chapter{Super Novo Método Revolucionário*}
A proposta de \MRLM~é fundamentada no \MML~\textit{dependent binary relevance} (DBR) \cite{dbr2014}, que é explicado
na seção \ref{sec:dbr}. Assim como o DBR, o \MRLMa~é um método baseado na transfomação do problema.
% portanto,
% esse capítulo é iniciado com uma seção explicando o funcionamento do DBR, facilitando o entendimento do \MRLMa~na seção seguinte.


\section{Algoritmo \MRLM~-~\MRLMa}
Como foi dito anteriormente, o \MRLM~é baseado no DBR. 
% Ambos se baseiam na expansão do espaço de características
% com características que representam a estimativas dos rótulos como forma de explorar
% a correlação entre rótulos. Isso é feito usando a predição do BR no espaço de características original.
% Ou seja, 
Ambos dependem da hipótese de que as estimativas dos rótulos em $Y$ por um classificador multirrótulo $c_0$
são boas características para aprimorar as estimativas dos mesmos rótulos por um novo classificador $c_1$
e que quanto melhor forem as estimativas dos rótulos por $c_0$, melhores são as de $c_1$. Nesse caso, podemos dizer
que o classificador $c_0$ é usado para "alimentar" o classificador $c_1$.
E ainda ambos usam o BR como classificador multirrótulo base, que servirá para realizar as primeiras estimativas dos 
rótulos.

No entanto, o \MRLMa, ao invés de usar apenas o classificador base $c_0$ para "alimentar" $c_1$, como o DBR,
ele usa o próprio $c_1$ para se "alimentar", ou seja, há realimentação pelo próprio classificador.
A idéia é que cada vez que $c_1$ se realimente, melhores ficam suas estimativas uma vez que ele será baseado
em estimativas melhores de rótulos do que anteriormente. 
A alimentação é a propagação das 
estimativas dos rótulos de um classificador multirrótulo para o espaço de características expandido de um outro, ou o mesmo,
classificador multirrótulo. O funcionamento do algoritmo serão formalmente detalhados nas seções seguintes.

Formalmente, a estrutura do \MRLMa~é organizado da seguinte forma:
\begin{itemize}
%   \item Assim como o DBR, é composto de dois classificadores multirrotulo, o primeiro, $c_0$, é um BR
%   e o segundo, $c_1$, é um BR ligeiramente modificado, que chamaremos de $BR^*$.
  \item Assim como o DBR, é composto de um BR e um classificador multirrótulo, $c_0$ e $c_1$,
  cada um composto de $l$ classificadores binários.
  \item O $c_0$ trabalha dentro do espaço de características original do problema, de nome $X$,
  e $c_1$ trabalha dentro de um novo espaço de características do problema, de nome $X_e$ e
   definido como $X_e=X \cup \{0,1\}^{l}$. Assim, $c_0$ e $c_1$ são
  representados pelas seguintes funções:
  \begin{equation}
  \begin{split}
   & c_0 : X \rightarrow \{0,1\}^l \\
   & c_1 : X_e \rightarrow \{0,1\}^l
   \end{split}
  \end{equation}
  \item Os $l$ classificadores binários $c_1^1,c_1^2...,c_1^l$ que compoêm $c_1$ não trabalham no mesmo
  espaço de características, contudo,
  trabalham com uma dimensão reduzida, em $X \cup \{0,1\}^{l-1}$. Digamos que $z=(z_1,z_2,...,z_l)$ seja uma instância de $X_e$, então cada instância 
  de um classificador binário qualquer $c_1^i$ tem $|X|+l-1$ características e é definido como sendo $(x,z_1,...,z_{i-1},z_{i+1},...,z_{l})$.

  
%   e o resultado da classificação multirrotulo de $c_1$ é construido da seguinte forma:
%   $c_0(x,y)=(c_1^1(x,y_2$
%   \item O método contém duas funções $t_0$ e $t_1$ que mapeiam espaços de características:
%    \begin{equation}
%  \begin{split}
%     & t_0 : X \rightarrow X_e \\
%     & t_1 : X_e \rightarrow X_e \\
%     & t_0(x)=(c_0(x)) | x \in X \\
%     & t_1(x,y)=(c_1(x,y)) | x \in X,  y \in [0,1]^{l}
% %   h_i : \mathbb{R}^l \rightarrow \mathbb{R}^l & | i=1,...,n-1
%   \end{split}
%  \end{equation}
%   
  
\end{itemize}

%  No entanto, o \MRLMa, ao invés de usar apenas dois classificadores, como o DBR, 
%  usa $n$ classificadores multirrótulo $c_0,c_1,...,c_{n-1}$ organizados em uma cadeia de tal forma que
%  as predições do classificador $c_{i-1}$ , para $1\leq i<n$, são usados como características para o classificador $c_{i}$. 
%  Dessa forma, o classificador $c_{i}$ será baseado em estimativas melhores de rótulos do que seus antecessores $c_{i-1},c_{i-2},...,c_0$ e ainda
%  o classificador $c_{i}$ será capaz de aprender sobre os erros e acertos do classificador $c_{i-1}$ e alcançar resultados melhores.
%  
%  Adicionalmente, o \MRLMa~assume que as características $\hat{y}_1,\hat{y}_2,...,\hat{y}_l$, estimados por um classificador multirrótulo,
%  são suficientes ou quase suficientes para predizer corretamente os valores reais dos rótulos em $Y$.
%  Baseado nessa suposição, o \MRLMa~substitue todas as características do espaço original pelas características $\hat{y}_1,\hat{y}_2,...,\hat{y}_l$,
%  para todos os seus classificadores, exceto para o classificador base $c_0$, uma vez que não existe ainda uma estimativa dos rótulos a usar.
%  Isso reduz o espaço de características o que diminui o custo computacional dos algoritmos.
%  Por outro lado, essa suposição nem sempre se mantém, podendo prejudicar a qualidade de predição dos algoritmos, mas espera-se que em média se mantenha.
 
%  Formalmente, a estrutura do \MRLMa~é organizado da seguinte forma:
%  \begin{itemize}
%   \item Para um valor pré-definido de n tal que $n\in \mathbb{N}, n>0$, o algoritmo é composto de
%   $n$ classsificadores BR que formam o conjunto $C=\{c_0,c_1,...,c_{n-1}\}$. 
%   \item Os classificadores em $C$ estão ordenados e dispostos em uma cadeia de tal forma que o 
%   classificador $c_i$ está ligado a saída (estimativas dos rótulos) do classificador $c_{i-1}$ e apenas a ele.
%   \item Cada classificador multirrótulo $c_i$ é composto de $l$ classificadores binários $h_{i1},h_{i2},h_{i3},...,h_{il}$
%   dispostos em uma cadeia.
%   
  
  Veja a figura \ref{fig:mrlm_struct} para visualizar a estrutura do \MRLMa. 
  
 
%   Lembrando que 
%   ao treinar $c_1$, treina-se um BR que gera $l$ problemas binários onde cada   rótulos a classificar são escondidos 
%   Portanto, apenas a fase de predição do algoritmo será detalhado nesse capítulo.
  
  
  
  
%   de tal forma que , para um $j\in \mathbb{N}, 0<j\leq l$, o $h_{ij}$ está ligado a $h_{i(j-1)}$ e somente a ele.
  
%  \end{itemize}

 
 
 \subsection{Fase de Treinamento}
  A fase de treinamento do \MRLMa~é exatamente igual ao DBR.
   
%   Diferencia-se apenas no classificador $c_1$, o qual no \MRLMa~é treinado somente com as características adicionais $Y$.
%   O objetivo de usar apenas os rótulos como características para treinar $c_1$ ao invés de usá-los juntamente com as
%   características originais é reduzir o espaço de características, reduzindo assim o custo computacional do algoritmo.
%   Essa idéia é baseada na hipótese de $c_1$ pode aprender a classificar corretamente um rótulo sabendo apenas
%   os valores do outros rótulos. É claro que ela nem sempre é verdade e com isso virá erros na classificação, entretanto
%   espera-se que ela se mantenha verdadeira, ou pelo menos que o erro seja pequeno,
%   pela suposição que exista correlação entre os rótulos no problema em que ele
%   for aplicado e também pelo fato de que os rótulos podem ser vistos como resumos das características do problema, e portanto
%   contém algumas informações do espaço de características original $X$, e assim nem toda informação que supostamente
%   é necessária para classificar um rótulo é descartada. Resumindo, espera-se que a queda no desempenho ao treinar $c_1$
%   usando apenas os rótulos seja relativamente pequeno quando comparado a queda no custo computacional do algoritmo.
  
  
  De forma mais formal, o treinamento de \MRLM~funciona da seguinte forma.
  Dado uma base de dados de treino $D=\{((x_i),y_i)|i=1,...,n\}$ onde $x_i \in X$ e $y_i \in Y$,
  primeiro treina-se o $c_0$
  no espaço de características original conforme o treinamento do próprio BR mostrado na seção \ref{sec:br}.
%   Depois, treina-se $c_1$ em uma nova base de dados $D'$ que é construída a partir de $D$ e que é
%   composta pelas instâncias $\{(y_1),(y_2),...,(y_n)\}$ as quais são os rótulos das instâncias da base de $D$
%   (ver figura \ref{fig:instsRotulos}).
  Depois, treina-se $c_1$ em uma nova base de dados $D'$ que é contruída a partir de $D$ adicionando os rótulos de cada
  exemplo como características. Assim, $D'$ é composta pelos exemplos $\{((x_i,y_i),y_i) |i=1,...,n\}$ e
  cada classificador binário $c_1^j$ de $c_1$ é induzido na base de dados $D'_j=\{(x_i,y_{i,1},...,y_{i,j-1},y_{i,j+1},...,y_{i,l}),y_{i,j} | i=1,...,n\}$.
  Note que a característica representando o $j$-ésimo rótulo é removido da base de dados.
  Dessa forma, ao invés de estimar apenas $P(y_j|x)$ como o BR faz, o método é capaz de detectar dependência entre os rótulos ao
  estimar $P(y_j|x,y_1,...,y_{j-1},y_{j+1},...,y_l)$.
%   , cada um representado na forma
%   binária na qual tem o valor $1$ se a instância tem o rótulo e $0$ se o contrário .
  
%  Dado uma base de treino $D$ composta de $n$ instâncias 
 
%  Formalmente, o \MRLMa~funciona da seguinte forma. Os classificadores em $c_0,c_1,...,c_{n-1} são representados
%  pelas funções $h_0,h_1,...,h_{n-1}$:
%  \begin{equation}
%  \begin{split}
%     & h_0 : X \rightarrow [0,1]^l \\
%     & h_i : [0,1]^l \rightarrow [0,1]^l | i=1,...,n-1
% %   h_0 : X \rightarrow \mathbb{R}^l &\\
% %   h_i : \mathbb{R}^l \rightarrow \mathbb{R}^l & | i=1,...,n-1
%   \end{split}
%  \end{equation}
%  
%  onde a imagem de cada função $h_i$ é um vetor $(\hat{y}_1,\hat{y}_2,...,\hat{y}_l)$ de tamanho $l$ onde cada elemento
%  $\hat{y}_i$ é um valor entre 0 e 1 que representa a pertinência de uma instância $t$ para o rótulo $i$ ou a probabilidade da instância $t$ pertencer
%  ao rótulo $i$.
%  
%  Primeiramente, treinamos o classificador BR $c_0$ no espaço de
%  características original $X$, resultando na construção da função $h_0(\bf{x})$:
%  \begin{equation}
%   h_0 : X \rightarrow \{0,1\}^l\.{z} 
%  \end{equation}
%  Em seguida, aplica-se a função $h_0$ sobre todas as instâncias da base de treino, resultando nas saídas
%  $h_0(x_1), h_0(x_2),...,h_0(x_n)$. A partir daí as instâncias são transformadas e mapeadas para um novo espaço de
%  características, criando a nova base de dados $D'$:
%  \begin{equation}
%   D'=\{(h_0(x_i),y_i)|i=1,...,n\}
%  \end{equation}

 
%  \begin{equation}
% \label{eq:funcT}
%   T : X \times Y \rightarrow \hat{Y} \times Y,~T(x,y)=(h_0(x),y)
%  \end{equation}
%  onde $\hat{Y}$ é composto por instâncias da forma:
%  \begin{equation}
%   x'=(h_0(\bf{x}))
%  \end{equation}


 
 \subsection{Fase de Predição}
 O funcionamento de \MRLMa~se distingue do DBR apenas na fase de predição.
 Dado uma instância $x$ onde $x\in X$ e seu conjunto de rótulos reais $y,y \in {\{0,1\}}^l$, queremos que a função $C:X\rightarrow Y$,
 representando o classificador multirrótulo \MRLMa, retorne $y$ quando o submetemos $x$, ou seja, $C(x)=y$.
 
 Como no caso do DBR e do Classifier Chain, os rótulos reais $y$, que são usado como características especiais,
 estão disponíveis apenas durante a fase de treinamento. Dessa forma, para tornar possível a classificação por $c_1$, usou-se o $c_0$ para
 estimar os rótulos, %  Para alcançar isso, o \MRLMa~, após treinado, usa $c_0$ para realizar as primeiras estimativas dos rótulos,
 resultando em $c_0(x)=\hat{y}^0=(\hat{y}_1^0,\hat{y}_2^0,...,\hat{y}_l^0)$, que servirá como parte da instância de $c_1$
 no lugar de $y$. 
 A partir daí, $c_1$ classifica a instância $(x,\hat{y}^0)$ de uma forma bem similar ao BR:
 cada classificador binário do método é responsável pela predição de um rótulo da instância.
%  \begin{equation}
%   c_1(x)=(c_1^1(x),c_1^2(x),...,c_1^l(x))
%  \end{equation}
 No entanto, o \MRLMa~adota uma técnica inspirada no Classifier Chain que consiste em, para
 cada classificador binário $c_1^j$, atualizar a característica $\hat{y}_j$ imediatamente após 
 a sua classificação. Dessa forma, os classificadores binários seguintes, $c_1^{j+1},c_1^{j+2},...,c_1^{l}$,
 classificarão suas instâncias baseados em estimativas de rótulos melhores.

 Assim que $c_1$ classifica a instância $(x,\hat{y}^0)$, gerando portanto a estimativa de rótulos $\hat{y}^1=c_1(x,\hat{y}^0)$,
 $\hat{y}^1$ é usado para atualizar as características da instância $x$, tomando assim o lugar de $\hat{y}^0$.
 Esse processo é chamado de ``realimentação'' pois, o classificador $c_1$ classifica baseado na sua própria classificação.
 A realimentação de $c_1$ é repetido $r$ vezes,
 onde $r$ é determinado por um valor máximo de realimentações, definido a priori, ou quando é detectado a convergência.
 Com $r$ realimentações, tem-se $r$ estimativas de rótulos $\hat{y}^1,\hat{y}^2,...,\hat{y}^r$, dentre as quais o último ($\hat{y}^r$)
 é a classificação final do método $C(x)=\hat{y}^r$.
 
 Dessa forma, podemos concluir que \MRLM~é um método recursivo que
 para $r=1$, $C(x)=c_1(c_0(x))$,
 para $r=2$, $C(x)=c_1(c_1(c_0(x)))$,
 para $r=3$, $C(x)=c_1(c_1(c_1(c_0(x))))$ e assim por diante.
 Note que para $r=0$, o \MRLMa~é exatamente o BR, $C(x)=c_0(x)$.
%  a aplicação de $c_1$ $3$ vezes sobre
%  $c_0(x)$ resulta na estimativa $\hat{y}^3=c_1(c_1(c_1(c_0(x))))$ e assim por diante.
 Aplicando esse processo recursivo, espera-se que a cada recursão $i$ a estimativa dos rótulos $\hat{y}^i$ seja melhor do que
 seu antecessor $\hat{y}^{i-1}$. Teoricamente, essa afirmação se mantém se supormos que a estimativa $\hat{y}^1$ é melhor do que a $\hat{y}^0$, 
 o que é razoável uma vez que o classificador $c_0$, que é um BR, obtem seu resultado usando apenas estimativas marginais dos rótulos,
 (@@@referenciar equacao de probabilidade marginal@@@)%  ($P(y|x)=\prod_{j=1}^l{P(y_j,x)}$)
 , enquanto que $c_1$ explora a correlação dos rótulos ao usá-los como características, obtendo assim 
 estimativas baseadas na probabilidade condicional.
 Com essa suposição teríamos que $\hat{y}^i$ seria melhor do que $\hat{y}^{i-1}$, pois $\hat{y}^{i-1}$ se aproxima
 mais da distribuição real dos rótulos do que $\hat{y}^{i-2}$. Assim, quando $c_1$ estimar $\hat{y}^i$ usando $\hat{y}^{i-1}$ estaria baseado em 
 uma distribuição mais próxima daquela em que foi treinado do que usando $\hat{y}^{i-2}$.
 Lembrando que $c_1$ foi treinado usando rótulos assumidamente corretos.
 
 Olhando por esse procedimento, o \MRLMa~pode ser simplesmente visto como um método que insere uma inteligência
 adicional a aplicação e uso do classificador $c_1$ de DBR, afim de que ele seja melhor aproveitado.
 
 
 
 \subsection{Análise}
 \begin{verbatim}
  -Listar as hipoteses/suposições em que MRLM é baseado.
  -Mostrar experimentos/gráficos que comprovam que as hipoteses bases
      são verdades(geralmente).
  -Conclusão rápida em relação a mudança que o MRLM faz com o DBR.
      (Conclusão mais detalhada será feita no último capitulo da monografia!)
 \end{verbatim}



\chapter{Avaliação e Análise Experimental}
\section{Método de Comparação}
\label{sec:methodcomp}

A comparação e estudo dos métodos é feita considerando o custo computacional e a qualidade de predição.
A qualidade de predição é estimada pelo método de avaliação por validação cruzada \ref{sec:modelav} com 10 \textit{folds}
sobre as \Nbases~bases de dados, todas apresentadas pela tabela \ref{tab:datas}.
Todas as bases de dados foram obtidas de repositórios públicos pelo seguinte
endereço virtual @@@.
Para quantificar a qualidade de predição, foram escolhidas as seguintes métricas, todas detalhadas na seção \ref{sec:metrics}:
% Hamming Loss, Accuracy, Subset Accuracy, Ranking Loss, ...@@@.

% As métrica escolhidas e os motivos pela qual foram escolhidas são os seguintes:
\begin{itemize}
 \item Subset Accuracy, pois é rígida @@@ etc...
 \item @@@
 \item @@@
 \item Tempo computacional, pois é @@@ etc...
\end{itemize}

É insteressante mostrar os resultados experimentais usando diferentes métricas, pois cada uma captura
um aspecto diferente da classificação.
No entanto, uma vez que é impossível obter uma única ordenação dos métodos
usando múltiplos critérios,
optou-se por usar a da média dos ranking das métricas como
o único critério de ordenação ao levantar pontos conclusivos sobre os métodos. 

Num total, foram comparados \Nml~\MML, \NmlT~da categoria de transformação e \NmlA~de adaptação @@@.
A comparação é antecedida por um estudo dos parâmetros dos métodos
cujo objetivo principal é encontrar os parâmetros que devem ser usadas na comparação dos métodos. Objetivos secundários são
espeficicados nas seções \ref{sec:study1} e \ref{sec:study2}, especialmente dedicadas para esse estudo.
O objetivo principal é alcançado ao analisar a alteração do comportamento dos métodos quando seus parâmetros são alterados.
O estudo dos parâmetros foi dividido em dois subestudos:
\begin{enumerate}
 \item estudo individual, que tem por objetivo analisar os parâmetros únicos de cada método individualmente.
  \item estudo de grupo, que tem por objetivo analisar os parâmetros que são idênticos para um grupo de métodos.
  Nesse caso o parâmetro que representa a escolha do classificador binário base para os método baseados em transformação é
  analisado. 
\end{enumerate}

O estudo de grupo tem como objetivo principal descobrir a melhor forma de comparar esses métodos entre si e
entre outros métodos, por exemplo, compara-los usando o mesmo parâmetro em cada um ou compara-los usando o melhor parâmetro
de cada um.


  Para mais detalhes sobre os motivos desse estudo bem como seus resultados e conclusões na seção \ref{sec:study1}.
  

\section{Estudo dos Métodos baseados em Transformação}
\label{sec:study1}
\begin{verbatim}
 -Listar métodos.
 -Falar como vai ser comparado cada método (teste estatístico, rankeamento, métrica boa) para comprovar a hipotese.
 -Apresentar resultados. (experimentos,tabela, gráficos...)
 -Conclusão sobre os resultados
\end{verbatim}

Nessa seção os \NmlT~\MMLs~de transformação são estudados com relação a suas qualidades. (@@@ listar os métodos de transfomação.)
A escolha do classificador base para cada um dos métodos foi reestrito para \Ncb~classificadores: @@@.
Esse subestudo tem como objetivo principal encontrar os classificadores $c_1^*,c_2^*,c_3^*,c_4^*,c_5^*$ que serão utilizados pelos
métodos $T_1,T_2,T_3,T_4,T_5$.
Para isso, analisou-se duas características:
  \begin{enumerate}
  
  \item a variação do ranking do método segundo um critério de qualidade ao variar o classificador base
  para uma base específica.
  \item a variação do ranking do classificador base segundo um critério de qualidade ao variar o método multirrotulo.
  \end{enumerate}

A comparação é realizada pelo rankeamento dos métodos, ou seja, os \MMLs~de transformação são submetidos a testes experimentais
e ordenados segundo seus desempenhos de tal forma que para cada métrica e classificador base,
é atribuído ao \MML~um valor correspondente a sua ordem, entre 1 e \NmlT. A ordenação por uma métrica
é independente da ordenação da outra. 
Os resultados experimentais são apresentados nas tabelas \ref{tab:study1-R-emotions},\ref{tab:study1-R-birds},..., uma para cada base de dados utilizada.
Por essas tabelas, já podemos observar as duas características desejadas, enumeradas anteriormente na seção \ref{sec:methodcomp},
mas para facilitar, construiu-se também as tabelas \ref{tab:study1-resumo}, que são resumos das tabelas ???.






\chapter{Conclusão}