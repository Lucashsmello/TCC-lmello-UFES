\newcommand{\NbasesV}{\textit{N}}
\newcommand{\Nbases}{8}
\newcommand{\Nml}{6}
\newcommand{\NmlT}{5}
\newcommand{\NmlA}{2}
\newcommand{\Ncb}{4}
\newcommand{\MML}{método multirrótulo}
\newcommand{\MMLs}{métodos multirrótulo}



\newcommand{\jqo}{C4.5}
\newcommand{\EBA}{\textit{Example Based Accuracy}}
\newcommand{\SA}{\textit{Subset Accuracy}}
\newcommand{\HL}{\textit{Hamming Loss}}

\newcommand{\BR}{\textit{Binary Relevance}}
\newcommand{\tabmode}{h}
% \newcommand{\legendaTab}[2]{Desempenho dos métodos multirrótulos com \textit{#2} medido pela métrica \textit{#1} }
\newcommand{\legendaTab}[2]{Desempenho dos métodos multirrótulos com \textit{#2} medidos pelas métricas \SA,\HL~e~\EBA}

\chapter{Introdução}
Segundo \cite{rezende2003sistemas} Aprendizado de Máquina é uma área da Inteligência Artificial
cujo objetivo é o desenvolvimento de técnicas computacionais
sobre o aprendizado bem como a construção de sistemas capazes de adquirir
conhecimento de forma automática. Dentro dessa área, encontra-se a subárea Aprendizado Supervisionado.
Em Aprendizado Supervisionado, um problema de classificação é a tarefa de encontrar
uma técnica capaz de predizer a classe ou as classes que uma instância
pertence \cite{rezende2003sistemas}.
Uma instância é um objeto do mundo real descrito
por um vetor de valores numéricos ou nominais e por um conjunto de rótulos.
Para completar essa tarefa, a técnica deve usar exemplos de treino cujas classes
são conhecidas. 
Na literatura \cite{rezende2003sistemas} as classes são também chamadas de rótulos
e quando as instâncias só podem assumir um único rótulo, o problema é chamado de classificação unirrótulo,
do contrário, é chamado de problema de classificação multirrótulo \cite{borges2012}.

Problemas de classificação multirrótulo estão presentes em diversas áreas, trabalhos relevantes podem
ser encontrados em áreas como a bioinfomática, diagnóstico médico, classificação de imagens e principalmente
categorização de textos, conforme \cite{carvalho2009}. A classificação multirrótulo é inevitavelmente
mais complexa que a unirrótulo. Para solucioná-la, o método multirrótulo mais conhecido é um método simples chamado de
Relevância Binária (do inglês \textit{Binary Relevance - BR}) \cite{carvalho2009}. 
No entanto, há muitas críticas sobre o \textit{BR}, sendo a maior delas a incapacidade do método de reconhecer
a correlação entre os rótulos, como dito por \cite{pcc2010}.
Com o intuito de alcançar melhores resultados que o \textit{BR}, alguns autores, como \cite{cc2009} e \cite{dbr2014},
o aprimoraram ou elaboraram novos tipos de métodos baseados nele,
os quais procuram explorar a dependência entre os rótulos. 
% Por exemplo, existem métodos que transformam o problema multirrótulo em
% diversos problemas unirrótulo, como é o caso do \textit{BR}, e outros métodos que são classificadores especiais,
% capazes de classificar diretamente sobre os problemas multirrótulo, sem necessidade de transformação, como é o caso do Multi-Label C4.5 (MADJAROV et al., 2012, p. 5). 

Com tantos métodos novos, alguns deles apresentados por \cite{carvalho2009}
e por \cite{cc2009} é necessário realizar comparações e testes de qualidade.
É certo que já existem análises e comparações entre os métodos,
no entanto há necessidade de avaliar os métodos mais formalmente
e reforçar as conclusões alcançadas pelos autores dos métodos.

\section{Motivações}
% A análise dos métodos multirrótulo traz os seguintes benefícios:
O melhor entendimento do funcionamento dos métodos multirrótulo permite:
\begin{itemize}
 \item descobrir atributos destes que se alterados, aproveitados
 e/ou combinados podem acarretar na criação de novos métodos e/ou na melhora dos existentes.
 \item prever, com uma certa taxa de erro, seus desempenhos, o que facilita o uso mais inteligente dos métodos
 sem precisar utilizar muito esforço computacional devido a testes.
 \item reforçar ou contrariar as conclusões já estabelecidas dos métodos, uma vez que a maioria delas são 
 baseadas em testes experimentais.
\end{itemize}

\section{Objetivos}
O objetivo geral deste trabalho é analisar e comparar métodos multirrótulos distintos e 
desenvolver um novo algoritmo de classificação multirrótulo.
Formalmente, a análise deve implicar em conclusões claros
sobre o desempenho dos métodos multirrótulo.
O Objetivo geral pode ser detalhado nos seguintes objetivos específicos:
\begin{itemize}
 \item Descobrir como medir e explorar correlação entre rótulos;
 \item Comparação estatística e análise crítica dos métodos multirrótulos;
 \item Elaboração de um algoritmo de um novo método multirrótulo;
 \item Implementação dos métodos multirrótulos em uma biblioteca que integra técnicas de reconhecimento de padrões.
\end{itemize}


% \section{Contribuições}
\section{Estrutura do Trabalho}
O restante do trabalho está organizado da seguinte forma:
\begin{itemize}
 \item O capítulo 2 apresenta os principais conceitos da classificação multirrótulo, bem como
 os métodos usados para avaliação de desempenho de classificadores multirrótulo.
 \item O capítulo 3 apresenta a definição de diferentes métodos de classificação multirrótulo usados neste trabalho,
 bem como suas complexidades algorítma.
 \item O capítulo 4 apresenta a definição de um novo método de classificação multirrótulo proposto neste trabalho.
 \item O capítulo 5 começa apresentando as configurações experimentais escolhidos para realização de testes e termina
 apresentando os resultados e a sua análise detalhada.
 \item No capítulo 6 são apresentados as conclusões finais sobre o desempenho dos métodos e sobre a análise do capítulo anterior.
\end{itemize}


\chapter{Classificação multirrótulo}

Problemas de classificação estão situadas na área de aprendizado supervisionado, que por sua vez é uma 
subárea da mineração de dados. Para \cite{dunham2003introductory} a mineração de dados é definido como a descoberta
de informações escondidas em um conjunto de dados. Ela surgiu diante do grande crescimento de dados armazenados
em arquivos de computadores e do desejo dos usuários desses dados em obter informações mais detalhadas do que simplesmente
os próprios dado em si. A mineração de dados tem por objetivo satisfazer o desejo desses usuários ao desenvolver técnicas
capazes de explicitar informações valiosas, antes escondidas ao usuários diante de uma alta quantidade de dados.
Uma de suas subáreas é a aprendizado supervisionado. Nela, segundo \cite{mohri2012foundations},
os dados pelos quais deve-se extrair as informações são divididos em amostras
e cada amostra está associado a uma variável especial, de valor conhecido,
e a técnica deve predizer o valor dessa variável especial para
novas amostras cujo valor da variável especial associada a elas é desconhecido. 
Normalmente, em aprendizado supervisionado os dados são objetos de um domínio específico e cada um dos objetos
é descrito por um conjunto fixo de atributos \cite{rezende2003sistemas}. 
Esses objetos são usualmente chamados de instâncias ou exemplos do domínio do problema.
Um atributo é uma descrição de uma característica da instância.
% Por exemplo, de um do ponto de vista médico cujo objetivo é diagnosticar 
% se um paciente está gripado ou não,

Em problemas de classificação unirrótulo, a variável especial associada a cada instância é discreta
e é chamada de classe ou rótulo. A técnica que prediz as classes é chamado de classificador.
Quando existem apenas duas classes, o problema é chamado de classificação binária.
% cada exemplo do objeto do domínio em questão é associado 
% a um único rótulo e o objetivo é desenvolver um sistema classificativo que consiga predizer corretamente
% o rótulo. 
Na classificação multirrótulo, cada instância pode assumir um ou mais rótulos, e a técnica
que prediz os rótulos de uma instância é chamada de classificador multirrótulo.
Por exemplo, uma instância de filme pode ser rotulado como sendo de romance e comédia, 
e não exclusivamente de romance ou comédia.

Assim a classificação é a tarefa de encontrar um classificador capaz de predizer 
o rótulo ou os rótulos de uma instância corretamente.
Para completar essa tarefa, o classificador deve usar dados de entrada que são exemplos
de treino cujos rótulos são conhecidos afim de
reconhecer e aprender padrões neles.

\section{Enunciado do problema}

Em um problema de classificação multirrótulo, seja $X$ o espaço de características tal que
$X\subseteq \mathbb{R}^n$ e $L=\{l_1,l_2,l_3,...l_r\}$ o conjunto dos $r$ rótulos possíveis do problema,
uma instância é definida como sendo uma dupla de vetores $(x',y')$ tal que $x'\in X$ e $y'$ é um vetor binário
$y'=(y'_1,y'_2,...,y'_r)$ de tal forma que $y'_i=1$ indica a presença do rótulo $l_i$ na instância.
Assim, o espaço de rótulos possíveis para uma instância qualquer é definido como $Y=\{0,1\}^r$.

% A tarefa do problema de classificação multirrótulo é encontrar uma função $C$, tal que $C : X \rightarrow Y$, de forma
% a maximizar uma métrica de qualidade, definida como uma função que mapeia as predições da função $C$
% e os rótulos reais alvos a um valor numérico de $0$ a $1$.
% A função $C$ é estimada a partir de uma base de treino $D=\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\}, x_i\in X, y_i\in Y$ e
% normalmente os classificadores multirrótulo são representados por essa função.

Seja $f$,$f : X \rightarrow Y$, a função que mapeia qualquer $x,x \in X$ a seus rótulos reais.
A tarefa do problema de classificação multirrótulo é encontrar a função $f$
a partir de uma base de treino $D=\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\}, x_i\in X, y_i\in Y$.
Uma vez que muito difícil encontrar $f$, ela é aproximada, resultando em $\hat{f}$.
Com isso, a tarefa do problema de classificação se torna em aproximar ao máximo $\hat{f}$ de $f$.
Formalmente, a aproximação é medida por uma métrica de qualidade é o objetivo é maximiza-la.


% e
% normalmente os classificadores multirrótulo são representados por essa função.

Note que em um problema de classificação unirrótulo todas as instâncias da forma $(x',y')$ tem como $y'$
um vetor binário de rótulos onde apenas uma posição tem valor $1$. Assim, podemos ver o problema classificação
unirrótulo como um caso específico do problema de classificação multirrótulo.
Outro ponto importante a notar é a grande diferença da complexidade da classificação unirrótulo para a multirrótulo.
Enquanto que na classificação unirrótulo o número de possíveis rotulações que uma instância desconhecida pode ter é
$r$, linear em relação ao número de rótulos, na multirrótulo o número cresce exponencialmente, a saber, $2^r$.
Assim construir um classificador multirrótulo é mais complexo que um classificador unirrótulo.

Alguns autores vêem os classificadores unirrótulo e os multirrótulo como uma função de probabilidade $p$ \cite{mcc2012}, \cite{pcc2010}.
No caso de classificadores unirrótulo, um classificador é uma função de probabilidade $p(y|x)$,
onde $y \in L$ e $x \in X$,
que estima a probabilidade da instância que tem o vetor de características $x$, ter o rótulo $y$.
Já no caso de classificadores multirrótulo, a função de probabilidade $p(y|x)$, onde $y \subseteq L$ e $x \in X$,
estima a probabilidade da instância que tem $x$, ter todos os rótulos em $y$.
Dessa forma, para um $x,x\in X$ qualquer, a função $\hat{f}$
pode ser obtida pela equação \ref{eq:funcprob}:
\begin{equation} \label{eq:funcprob}
 \hat{f}=\operatorname*{arg\,max}_{y^*} p(y|x)
\end{equation}
Apesar da função $\hat{f}$ ser melhor aproximada de $f$ quando obedece a equação \ref{eq:funcprob}, 
muitos métodos multirrótulos não a obedecem por ser muito custoso de estimá-la, uma vez que existe
procurar $y^*$ dentre $2^r$ possíveis combinações.



\section{Avaliação de Desempenho}
A avaliação de desempenho de classificadores, tanto multirrótulo quanto unirrótulo, é comumente feito
por meio de testes nas amostras coletadas do problema.
Isso é feito corretamente com a ajuda de métodos de reamostragem fundamentados pela ciência estatística,
descritas na seção \ref{sec:modelav}.

A avaliação de desempenho dos classificadores multirrótulos se difere da unirrótulo principalmente na
quantificação da qualidade de predição. Enquanto que na classificação unirrótulo existe somente uma classificação
correta dentre apenas $r$ possíveis classificações, na classificação multirrótulo podem existir mais de uma combinação, 
dentre as $2^r$ possíveis, que estejam corretas ou parcialmente corretas.
Para isso, são definidas várias métricas multirrótulo na seção \ref{sec:metrics},
cada uma capturando um aspecto diferente do desempenho do classificador. 



\subsection{Métricas}
\label{sec:metrics}

Seja $P=(p_1,p_2,...,p_n), p_i \subseteq L$
% $\hat{y}=(\hat{y}_1,\hat{y}_2,...,\hat{y}_n), \hat{y}_i \in Y$
um vetor de predições de rótulos produzido pela
classificação das $n$ instâncias de rótulos $(r_1,r_2,...,r_n), r_i \subseteq L$
% da base $D=\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\}, x_i\in X, y_i\in Y$
respectivamente. Note que aqui as predições $p_i$ e os rótulos $r_i$ estão representados na forma de conjunto de rótulos,
e não na forma de vetor binário.
As métricas multirrótulo propostas servem para quantificar a qualidade de $P$
e úteis para resumi-lo a um único valor escalar entre 0 e 1.
Abaixo estão algumas métricas definidas por \cite{reviewml2013}:

\subsubsection{Hamming Loss}
\begin{equation}
 hloss(P)=\frac{1}{n} \sum_{i=1}^n{\frac{1}{|L|}|p_i \triangle r_i|}
\end{equation}
O símbolo $\triangle$ é definido como a diferença simétrica entre dois conjuntos, por exemplo, 
para quaisquer $A$ e $B$, $A \triangle B=(A \cup B) - (A \cap B)$.
O \textit{Hamming Loss} significa a proporção de rótulos preditos mal classificados. Por rótulo predito mal classificado
entende-se que classificou um rótulo que não existia ou deixou de classificar um rótulo relevante.
Note que quanto menor o seu valor, melhor é a qualidade de predição, sendo que 0 é a qualidade perfeita e 1 a mais
imperfeita possível.

Em \cite{pcc2010} é mostrado que para que um classificador minimize o valor dessa métrica, basta minimizar
o erro (mal classificação) para cada rótulo individualmente. 
Assim, para minimizar essa métrica não é necessário levar
em consideração a correlação entre rótulos. Dessa forma considerar os rótulos de forma independente é o suficiente para minimizá-lo,
apesar de que um método multirrótulo pode usar a correlação entre rótulos para ajudar a minimizá-lo, uma vez que 
a tarefa de classificação, mesma que de forma independente, é difícil.

\subsubsection{Subset Accuracy}
\begin{equation}
 subsetAcc(P)=\frac{1}{n} \sum_{i=1}^n{\text{\textlbrackdbl} p_i = r_i \text{\textrbrackdbl}}
\end{equation}
O \SA~avalia a proporção de instâncias corretamente classificados. Aqui, nessa métrica, 
entende-se por instância corretamente classificado quando o conjunto de rótulos preditos é
idêntico ao conjunto de rótulos reais. É uma métrica rígida cujo valor ideal é 1 enquanto
que o menor valor possível é 0.

Em \cite{pcc2010} é mostrado que para maximizar o valor dessa métrica, é necessário levar
em consideração a dependência entre rótulos. É por isso que ele é considerado nesse trabalho
uma métrica que exige que o classificador multirrótulo explore a correlação entre rótulos.


\subsubsection{Example Based Accuracy}
\begin{equation}
 exampleAcc(P)=\frac{1}{n} \sum_{i=1}^n{\frac{| p_i \cap r_i|}{| p_i \cup r_i|}}
\end{equation}

Note que para essa métrica o valor de melhor desempenho é 1 e o de pior desempenho é 0.

% \subsubsection{Precision}
% \subsubsection{Recall}
\subsection{Método de Reamostragem}
\label{sec:modelav}

Um método de reamostragem é um modelo ou processo de avaliação para estimar valores estatísticos
(no nosso caso, as métricas definidas na seção \ref{sec:metrics}) usando apenas subconjuntos dos dados
disponíveis \cite{yu2003resampling}.
O método de reamostragem (ou modelo de avaliação) é diferente da métrica de avaliação,
pois define como o classificador deve ser avaliado, enquanto que a métrica mede o desempenho, dando um
valor para ele.

Na área de Aprendizado Supervisionado, um dos métodos de reamostragem mais usado é a Validação Cruzada.
Para um $k$ pré-definido maior que 1, a Validação Cruzada consiste
em dividir o conjunto de dados $D$
em $k$ subconjuntos disjuntos de tamanhos iguais
,$\{s_1,s_2,...,s_k\}$ tal que $s_1 \cup s_2 \cup s_3...s_{k-1}\cup s_k=D$,
e realizar $k$ testes, enumerados de 1 a $k$.
Cada teste $i$, para $1\leq i \leq k$, separa um desses subconjuntos
para formar a base de dados de teste
enquanto os restantes formam a base de dados de treino. 
Em seguida, o modelo de classificação é treinado sobre a base de treino e testado sobre todas as
instâncias da base de teste.
No final, juntando os $k$ testes, temos uma classificação (predição) para cada instância de $D$.
A partir daí aplica-se as métricas de avaliação, como por exemplo o \HL.


\chapter{Métodos Multirrótulos}
\section{Relevância Binária - BR}
\label{sec:br}


O método da Relevância Binária, conhecido como \textit{Binary Relevance} \cite{br2010}, 
é composto de $r$ classificadores binários $c_1,c_2,...,c_r$. Cada classificador $c_i$ 
é associado ao rótulo $i$ e treinado com o único objetivo de resolver
um problema de classificação binária onde as instâncias que
tem o rótulo $r_i$ são consideradas para o classificador $c_i$ como positivas
e as demais instâncias como
negativas. 
Após todos os classificadores terem sido treinados, quando uma instância
de rótulo desconhecido 
é apresentado aos classificadores, todos aqueles que produzirem uma classe positiva
terão sua classe associada à nova instância.
O método de classificação de relevância binária é uma estratégia de transformação do
problema, que decompõe o problema de classificação multirrótulo em diversos problemas
de classificação binária unirrótulo, um para cada um dos rótulos do problema.

\begin{figure}
 \includegraphics[width=1\linewidth]{BR-figure2}
 
 \caption{Exemplo da transformação realizada pelo método \textit{BR}}
\label{fig:br}

\end{figure}

A figura \ref{fig:br} ilustra um exemplo da transformação que o BR realiza em um problema multirrótulo
de rótulos $A,B$ e $C$ e 6 instâncias. Nele vemos que o BR transforma a base de treino em 3 novas bases
de dados, um para cada classificador binário.





\section{Classifier Chain}


A idéia básica desse algoritmo é semelhante ao BR: realiza a transformação do
problema multirrótulo decompondo-o em diversos problemas
de classificação binária unirrótulo, um para cada um dos rótulos do problema.
Ele é também composto de $r$ classificadores binários $c_1,c_2,...,c_r$ e cada um
é associado a um único rótulo distinto. A diferença do \textit{Classifier Chain} para o BR está
em que os classificadores binários estão organizados em uma cadeia de tal forma que
o classificador $c_i$ é contruído com base nos rótulos ou predições dos classificadores anteriores
($c_{i-1},c_{i-2},...,c_{1}$) \cite{cc2009}. O classificador $c_i$ não está necessariamente associado ao rótulo $r_i$,
ele pode estar associado a qualquer um dos rótulos.
Essa associação é feita de forma aleatória ou pré-definida por parâmetro do algoritmo.

Na fase de treinamento do método o espaço de características de cada classificador $c_i$ é 
extendido com os valores dos $i-1$ rótulos reais anteriores da cadeia. Veja um exemplo 
ilustrado na figura \ref{fig:CCtraintest} onde o método é treinado sobre uma base de treino de três rótulos ($A,B,C$)
e seis instâncias. Note que a base de treino do classificador binário $B$ tem como característica adicional o rótulo $A$.

Na fase de predição do método a classificação ocorre de forma sequencial, na ordem em que a cadeia foi definida.
O classificador $c_1$ inicia o processo de classificação realizando a estimativa do rótulo associado da instância teste.
A partir daí o classificador $c_i$ realiza a predição da instância teste assim que a predição do classificador $c_{i-1}$
estiver disponível. O classificador $c_i$ agrega a predição do classificador $c_{i-1}$, que é um valor binário (0 ou 1),
a instância de teste. A figura \ref{fig:CCtraintest} ilustra bem o processo de predição na qual o vetor de características da
instância teste vai crescendo com adição de cada estimativa de rótulo.

Dessa forma, o \CC~considera a dependência entre os rótulos, pois a predição de um de seus classificadores binários
afeta diretamente na predição dos classificadores binários seguintes.

\begin{figure}

 \includegraphics[width=1\linewidth]{CC-train-test}
 \caption{Ilustração de um exemplo da fase de treinamento e de predição do método Classifier Chain.}
\label{fig:CCtraintest}
\end{figure}


\section{Ensemble of Classifier Chain}
O \textit{Ensemble of Classifier Chain} é composto de $k$ \textit{Classifiers Chain} distintos \cite{cc2009},
para um $k$ pré-definido.
Para cada um dos $k$ \textit{Classifiers Chain} é definido uma ordem aleatória da cadeia e
cada um é treinado sobre um amostra aleatória da base de dados de treino.
Na fase de predição, a instância é submetida a todos os \textit{Classifiers Chain}, resultando
em $k$ predições individuais para uma mesma instância. A predição final é feita combinando 
as $k$ predições individuais,
sendo feito por voto majoritário, ou seja, um rótulo $y$ estará na predição final se $y$ estiver
em pelo menos $\ceil{\frac{k}{2}}$ das predições individuais.
O motivo para que cada \textit{Classifier Chain} do \textit{Ensemble} ser diferente é que
ao combinar um classificador $\textbf{c}$ com outros classificadores diferentes,
espera-se que nas instâncias em que $\textbf{c}$ classificar incorretamente,
a maior parte dos outros classificadores classifiquem corretamente.


\section{Relevância Binária Dependente - DBR}
\label{sec:dbr}
Este método é proposto por \cite{dbr2014} e é baseado no método BR
e a grande diferença entre ambos está no fato de 
que o DBR considera dependência entre os $r$ rótulos.

O DBR é composto de dois classificadores multirrótulo, $c_0$ e $c_1$ , 
cada um composto de $r$ classificadores binários. O classificador multirrótulo $c_0$ é
exatamente o método BR. Os $r$ classificadores binários $c_1^1,c_1^2...,c_1^r$ que compoêm $c_1$ 
  trabalham em um novo espaço de características $X^{new}=X \times \{0,1\}^{r-1}$.
  Esse novo espaço é a extensão do antigo com a adição de $r-1$ rótulos.
  Digamos que $(x,y)$ seja uma instância do espaço original $X \times Y$
  onde $x \in X$ e $y \in {\{0,1\}}^{r}$, então cada instância
  do classificador binário $c_1^i$ tem $|x|+r-1$ características
  e é definido como sendo $(x,y_1,...,y_{i-1},y_{i+1},...,y_{r})$.
  
  \subsection{Fase de Treinamento}
  Seja $D=\{((x_i),y_i)|i=1,...,n\}$ a base de dados de treino composta de $n$ instâncias,
  onde $x_i \in X$ e $y_i \in Y$,
  $x_i$ é o vetor de características de cada instância
  e $y_i$ o vetor binário de rótulos de cada instância.
  O método primeiro treina o $c_0$
  no espaço de características original conforme o treinamento do próprio BR mostrado na seção \ref{sec:br}.
  Depois, treina-se $c_1$ em uma nova base de dados $D'$ que é construída a partir de $D$ ao adicionar os rótulos de cada
  exemplo como características.
  Assim, $D'$ é composta pelos exemplos $\{((x_i,y_i),y_i) |i=1,...,n\}$ e
  cada classificador binário $c_1^j$ de $c_1$ é induzido na base de dados
  $D'_j=\{(x_i,y_{i,1},...,y_{i,j-1},y_{i,j+1},...,y_{i,r}),y_{i,j} | i=1,...,n\}$.
  Note que a característica representando o $j$-ésimo rótulo é removido da base de dados.
  Dessa forma, ao invés de cada classificador binário ser uma função 
  que depende apenas do vetor de características, como o BR,
  o método é capaz de detectar dependência entre os rótulos pelo fato de
  cada classificador binário $c_1^j$ 
  ser definido por uma função que depende adicionalmente dos valores dos rótulos sendo preditos.
%   $P(y_j|x,y_1,...,y_{j-1},y_{j+1},...,y_r)$.
  
  \subsection{Fase de Predição}
  Como no caso do Classifier Chain, os rótulos reais $y$, que são usados como características adicionais em cada instância de treino,
 estão disponíveis apenas durante a fase de treinamento.
 Com isso, para tornar possível a classificação por $c_1$, o DBR usa o classificador $c_0$ com a finalidade de
 estimar os rótulos, %  Para alcançar isso, o \MRLMa~, após treinado, usa $c_0$ para realizar as primeiras estimativas dos rótulos,
 o que resulta no predição $c_0(x)=\hat{y}=(\hat{y}_1,\hat{y}_2,...,\hat{y}_r)$, 
 que servirá como parte da instância a ser classificada por $c_1$,
 onde antes era o lugar de $y$. 
 A partir daí, $c_1$ classifica o vetor de características $(x,\hat{y})$ de uma forma bem similar ao BR:
 cada classificador binário $c_1^i$ do método é responsável pela predição de um único rótulo da instância
 cujo vetor de características é $(x,\hat{y}_1,...,\hat{y}_{j-1},\hat{y}_{j+1},...,\hat{y}_r)$.

\section{Monte Carlo Classifier Chain}


O método \textit{Classifier Chain with Monte Carlo Optimization} (MCC) é introduzido
por \cite{mcc2012} para melhorar a qualidade de predição do \textit{Classifier Chain}.
O método usa uma heurística gulosa para melhorar a fase de predição do \textit{Classifier Chain}.
O método parte do pressuposto de que o \textit{Classifier Chain} geralmente não encontra
o conjunto de rótulos $y^*,y^* \in {\{0,1\}}^r$ cuja probabilidade da instância ter seja máxima, ou seja, 
não segue corretamente a equação \ref{eq:funcprob}.
Para encontrar o $y^*$ de maior probabilidade, a princípio deve-se procurá-lo em todas as possíveis
combinações de ${\{0,1\}}^r$, o que torna-se inviável para um valor de $r>10$.
O MCC tenta encontrar esse $y^*$ sem testar todas as possíveis $2^r$ combinações do espaço de busca.
Ele usa de um algoritmo de otimização, chamado \textit{Monte Carlo} \cite{montecarlo}, para
testar apenas algumas dessas combinações.



 

% \section{Adaptação de classificadores}
% \subsection{ML-KNN}
% \subsection{Rede Neural Artificial}
% \subsection{C4.5 multirrótulo}
% \subsection{CRankSVM}
% \subsection{MAIS...}


\chapter{Recursive Dependent Binary Relevance - RDBR}
A proposta de \MRLM~(\MRLMa)~é fundamentada no \MML~\textit{dependent binary relevance} (DBR) \cite{dbr2014}, que é explicado
na seção \ref{sec:dbr}. Assim como o DBR e o CC, o \MRLMa~é um método baseado na transformação do problema que dividem o problema
multirrótulo em vários problemas classificação binária. Todos eles exploram a correlação entre os rótulos por meio da adição de
características especiais que representam os rótulos reais ou estimativas dos rótulos reais ao espaço de características original. 
Mas, diferentemente dos outros, o \MRLMa~adiciona uma inteligência no uso dessas características especiais na fase de predição do método.
A forma de como isso é feito, bem como o funcionamento completo do algoritmo de classificação e a fundamentação teórica
do \MRLMa~são detalhados na seção \ref{sec:mrlm_algo}. 
A seção \ref{sec:mrlm_analise} analisa o funcionamento e o desempenho do \MRLMa~de forma empírica.


\section{Algoritmo de \MRLM~-~\MRLMa}
\label{sec:mrlm_algo}
Como foi dito anteriormente, o \MRLM~é baseado no DBR. 
% Ambos se baseiam na expansão do espaço de características
% com características que representam a estimativas dos rótulos como forma de explorar
% a correlação entre rótulos. Isso é feito usando a predição do BR no espaço de características original.
% Ou seja, 
Ambos dependem da hipótese de que as estimativas dos rótulos em $Y$ por um classificador multirrótulo $c_0$
são boas características para aprimorar as estimativas dos mesmos rótulos por um novo classificador $c_1$
e que quanto melhor forem as estimativas dos rótulos por $c_0$, melhores são as de $c_1$.
% Nesse caso, podemos dizer
% que o classificador $c_0$ é usado por $c_1$ como parâmetro para .
E ainda ambos usam o BR como classificador multirrótulo base, que servirá para realizar as primeiras estimativas dos 
rótulos.

No entanto, o \MRLMa, ao invés de usar apenas o classificador base $c_0$ como função para contruir
as características adicionais que o $c_1$ usa, como o DBR,
ele também usa o próprio $c_1$ para essa finalidade, ou seja, há uma atualização das estimativas das características
pelo próprio classificador que as usam.
A idéia é que cada vez que $c_1$ as atualiza, melhores ficam suas estimativas uma vez que ele será baseado
em estimativas melhores de rótulos do que anteriormente. 
% A alimentação é a propagação das 
% estimativas dos rótulos de um classificador multirrótulo para o espaço de características expandido de um outro, ou o mesmo,
% classificador multirrótulo.
O funcionamento do algoritmo é detalhado nas subseções \ref{sec:mrlm_train} e \ref{sec:mrlm_prediction}.
Formalmente, a estrutura do \MRLMa~é organizado da seguinte forma:
\begin{itemize}
%   \item Assim como o DBR, é composto de dois classificadores multirrotulo, o primeiro, $c_0$, é um BR
%   e o segundo, $c_1$, é um BR ligeiramente modificado, que chamaremos de $BR^*$.
  \item Assim como o DBR, é composto de um BR e um classificador multirrótulo, $c_0$ e $c_1$,
  cada um composto de $r$ classificadores binários.
  \item O $c_0$ trabalha dentro do espaço de características original do problema, de nome $X$,
  e $c_1$ trabalha dentro de um novo espaço de características do problema, de nome $X_e$ e
   definido como $X_e=X \times \{0,1\}^{r}$. Assim, $c_0$ e $c_1$ são
  representados pelas seguintes funções:
  \begin{equation}
  \begin{split}
   & c_0 : X \rightarrow \{0,1\}^r \\
   & c_1 : X_e \rightarrow \{0,1\}^r
   \end{split}
  \end{equation}
  \item Os $r$ classificadores binários $c_1^1,c_1^2...,c_1^r$ que compoêm $c_1$ não trabalham no mesmo
  espaço de características, contudo,
  trabalham com uma dimensão reduzida, em $X \times \{0,1\}^{r-1}$. Digamos que $(x,y)$ seja uma instância de $X_e$
  onde $x \in X$ e $y \in {\{0,1\}}^r$, então cada instância 
  do classificador binário $c_1^i$ tem $|x|+r-1$ características e é definido como sendo $(x,y_1,...,y_{i-1},y_{i+1},...,y_{r})$.

  
%   e o resultado da classificação multirrotulo de $c_1$ é construido da seguinte forma:
%   $c_0(x,y)=(c_1^1(x,y_2$
%   \item O método contém duas funções $t_0$ e $t_1$ que mapeiam espaços de características:
%    \begin{equation}
%  \begin{split}
%     & t_0 : X \rightarrow X_e \\
%     & t_1 : X_e \rightarrow X_e \\
%     & t_0(x)=(c_0(x)) | x \in X \\
%     & t_1(x,y)=(c_1(x,y)) | x \in X,  y \in [0,1]^{l}
% %   h_i : \mathbb{R}^l \rightarrow \mathbb{R}^l & | i=1,...,n-1
%   \end{split}
%  \end{equation}
%   
  
\end{itemize}
  As seções seguintes explicam o funcionamento da estrutura apresentada 
  bem como formalizam e detalham tanto a fase de treinamento quanto a fase de predição do algoritmo.
  É importante observar que a fase de treinamento do \MRLMa~é exatamente o mesmo do que o DBR.
  A diferença de ambos os métodos se dá na fase de predição, descrita na seção \ref{sec:mrlm_prediction}.
 
 
 \subsection{Fase de Treinamento}
 \label{sec:mrlm_train}
  A fase de treinamento do \MRLMa~é exatamente igual ao DBR.
  
  Formalmente, o treinamento de \MRLM~funciona da seguinte forma.
  Seja $D=\{((x_i),y_i)|i=1,...,n\}$ a base de dados de treino composta de $n$ instâncias,
  onde $x_i \in X$ e $y_i \in Y$,
  $x_i$ é o vetor de características de cada instância
  e $y_i$ o vetor binário de rótulos de cada instância.
%   Dado uma base de dados de treino $D=\{((x_i),y_i)|i=1,...,n\}$ onde $x_i \in X$ é o vetor de características de cada instância
%   e $y_i \in Y$ o vetor binário de rótulos de cada instância,
  O algoritmo primeiro treina o classificador multirrótulo $c_0$
  no espaço de características original conforme o treinamento do próprio BR mostrado na seção \ref{sec:br}.
%   Depois, treina-se $c_1$ em uma nova base de dados $D'$ que é construída a partir de $D$ e que é
%   composta pelas instâncias $\{(y_1),(y_2),...,(y_n)\}$ as quais são os rótulos das instâncias da base de $D$
%   (ver figura \ref{fig:instsRotulos}).
  Depois, treina-se $c_1$ em uma nova base de dados $D'$ que é construída a partir de $D$ adicionando os rótulos de cada
  exemplo como características. Assim, $D'$ é composta pelos exemplos $\{((x_i,y_i),y_i) |i=1,...,n\}$ e
  cada classificador binário $c_1^j$ de $c_1$ é induzido na base de dados $D'_j=\{(x_i,y_{i,1},...,y_{i,j-1},y_{i,j+1},...,y_{i,r}),y_{i,j} | i=1,...,n\}$.
  Note que a característica representando o $j$-ésimo rótulo é removido da base de dados.
  Dessa forma, ao invés de cada classificador binário ser uma função 
  que depende apenas do vetor de características, como o BR,
  o método é capaz de detectar dependência entre os rótulos pelo fato de
  cada classificador binário $c_1^j$ 
  ser definido por uma função que depende adicionalmente dos valores dos rótulos sendo preditos.
%   Dessa forma, ao invés de estimar apenas $P(y_j|x)$ como o BR faz, o método é capaz de detectar dependência entre os rótulos ao
%   estimar $P(y_j|x,y_1,...,y_{j-1},y_{j+1},...,y_r)$.
 
 \subsection{Fase de Predição}
 \label{sec:mrlm_prediction}
 O funcionamento do \MRLMa~distingue-se do DBR apenas na fase de predição.
 Dado o vetor de características $x$ de uma instância 
 onde $x\in X$ e seu conjunto de rótulos reais $y,y \in {\{0,1\}}^r$, queremos que a função $C$
 representando o classificador multirrótulo \MRLMa, onde $C:X\rightarrow Y$,
 retorne $y$ quando o submetemos $x$, ou seja, $C(x)=y$.
 
 Como no caso do DBR e do Classifier Chain, os rótulos reais $y$, que são usado como características especiais,
 estão disponíveis apenas durante a fase de treinamento.
 Dessa forma, para tornar possível a classificação por $c_1$, 
 usou-se o classificador multirrótulo $c_0$ para
 estimar os rótulos, %  Para alcançar isso, o \MRLMa~, após treinado, usa $c_0$ para realizar as primeiras estimativas dos rótulos,
 resultando em $c_0(x)=\hat{y}^0=(\hat{y}_1^0,\hat{y}_2^0,...,\hat{y}_r^0)$,
 que servirá como parte da instância de $c_1$
 no lugar de $y$. 
 A partir daí, $c_1$ classifica o vetor de características $(x,\hat{y}^0)$ de uma forma bem similar ao BR:
 cada classificador binário $c_1^i$ do método é responsável pela predição de um único rótulo da instância
 cujo vetor de características é $(x,\hat{y}_1^0,...,\hat{y}_{j-1}^0,\hat{y}_{j+1}^0,...,\hat{y}_r^0)$. 
 Esse procedimento é o realizado pelo DBR e é ilustrado na figura \ref{fig:DBRstruct}. 
 Nela vemos quais estimativas de rótulos são utilizadas como características adicionais para classificação final
 de uma instância.
 
   \begin{figure}
\centering
$
\psmatrix[colsep=.6cm,rowsep=.4cm,linewidth=.4pt]
\\
\\
& \bigcirc &\circ&&\bigcirc&\enspace&\\
&\vdots\\
& \bigcirc &\circ&&\bigcirc&\enspace&\\
&\vdots\\
& \bigcirc &\circ&&\bigcirc&\enspace&\\
&\mathrm{BR}&&&\mathrm{DBR}
\ncline[linestyle=dotted]{3,3}{3,5}
\ncput*[npos=.65]{\|}
\ncline[linestyle=dotted]{5,3}{5,5}
\ncput*[npos=.65]{\|}
\ncline[linestyle=dotted]{7,3}{7,5}
\ncput*[npos=.65]{\|}
\ncline{->}{3,2}{3,3}
\ncline{->}{5,2}{5,3}
\ncline{->}{7,2}{7,3}
\ncline{->}{3,3}{5,5}
\ncline{->}{3,3}{7,5}
\ncline{->}{5,3}{3,5}
\ncline{->}{5,3}{7,5}
\ncline{->}{7,3}{3,5}
\nccircle[linestyle=none]{3,3}{.01cm}_{\hat{y}_1}
\nccircle[linestyle=none]{5,3}{.01cm}_{\hat{y}_j}
\nccircle[linestyle=none]{7,3}{.01cm}_{\hat{y}_r}
\nccircle[linestyle=none]{3,6}{.01cm}_{\hat{y}_1}
\nccircle[linestyle=none]{5,6}{.01cm}_{\hat{y}_j}
\nccircle[linestyle=none]{7,6}{.01cm}_{\hat{y}_r}
\ncline[arm=50pt]{->}{7,3}{5,5}
\ncline{->}{3,5}{3,6}
\ncline{->}{5,5}{5,6}
\ncline{->}{7,5}{7,6}
\nccircle[linestyle=none]{3,5}{.12cm}>{ c_1^0 }
\nccircle[linestyle=none]{5,5}{.12cm}>{ c_1^j }
\nccircle[linestyle=none]{7,5}{.12cm}>{ c_1^r }
\nccircle[linestyle=none]{3,2}{.12cm}>{ c_0^0 }
\nccircle[linestyle=none]{5,2}{.12cm}>{ c_0^j }
\nccircle[linestyle=none]{7,2}{.12cm}>{ c_0^r }
\endpsmatrix
$
\caption{Arquitetura do classificador \textit{Dependent Binary Relevance} (DBR).
Na primeira camada (a esquerda), os classificadores binários do BR proveem cada
um dos rótulos individualmente. A próxima camada provê a estimativa final dos rótulos.}
\label{fig:DBRstruct}
\end{figure}
 
   \begin{figure}
\centering
$
\psmatrix[colsep=.6cm,rowsep=.4cm,linewidth=.4pt]
\\
\\
& \bigcirc &\circ&&\bigcirc&\circ&\\
&\vdots\\
& \bigcirc &\circ&&\bigcirc&\circ&\\
&\vdots\\
& \bigcirc &\circ&&\bigcirc&\circ&\\
&\mathrm{BR}&&&\mathrm{RDBR}
\ncline[linestyle=dotted]{3,3}{3,5}
\ncput*[npos=.65]{\|}
\ncline[linestyle=dotted]{5,3}{5,5}
\ncput*[npos=.65]{\|}
\ncline[linestyle=dotted]{7,3}{7,5}
\ncput*[npos=.65]{\|}
\ncline{->}{3,2}{3,3}
\ncline{->}{5,2}{5,3}
\ncline{->}{7,2}{7,3}
\ncline{->}{3,3}{5,5}
\ncline{->}{3,3}{7,5}
\ncline{->}{5,3}{3,5}
\ncline{->}{5,3}{7,5}
\ncline{->}{7,3}{3,5}
\nccircle[linestyle=none]{3,3}{.01cm}_{\hat{y}_1}
\nccircle[linestyle=none]{5,3}{.01cm}_{\hat{y}_j}
\nccircle[linestyle=none]{7,3}{.01cm}_{\hat{y}_r}
\nccircle[linestyle=none]{3,6}{.01cm}_{\hat{y}_1}
\nccircle[linestyle=none]{5,6}{.01cm}_{\hat{y}_j}
\nccircle[linestyle=none]{7,6}{.01cm}_{\hat{y}_r}
\ncline[arm=50pt]{->}{7,3}{5,5}
\ncline{->}{3,5}{3,6}
\ncline{->}{5,5}{5,6}
\ncline{->}{7,5}{7,6}
\ncloop[arm=.7,loopsize=0,angleA=90,angleB=90]{->}{3,6}{3,3}
\ncloop[arm=.7,loopsize=0,angleA=90,angleB=90]{->}{5,6}{5,3}
\ncloop[arm=.7,loopsize=0,angleA=90,angleB=90]{->}{7,6}{7,3}
\nccircle[linestyle=none]{3,5}{.12cm}>{ c_1^0 }
\nccircle[linestyle=none]{5,5}{.12cm}>{ c_1^j }
\nccircle[linestyle=none]{7,5}{.12cm}>{ c_1^r }
\nccircle[linestyle=none]{3,2}{.12cm}>{ c_0^0 }
\nccircle[linestyle=none]{5,2}{.12cm}>{ c_0^j }
\nccircle[linestyle=none]{7,2}{.12cm}>{ c_0^r }
\ncline{->}{3,6}{3,7}
\ncline{->}{5,6}{5,7}
\ncline{->}{7,6}{7,7}
\endpsmatrix
$
\caption{ Arquitetura do \textit{Recursive Dependent Binary Relevance} (RDBR).
Na primeira camada (a esquerda), os classificadores binários do BR proveem estimativas de cada
um dos rótulos individualmente. A próxima camada provê as estimativas obtidas pelo DBR as quais
são usados recursivamente ao realimentar o DBR.
% The realimentation to obtain $\hat{\yy}^{\mathrm{(\tau+1)}}$
% is only performed when the complete estimated
% label vector from the current iteration $\hat{\yy}^{\mathrm{(\tau+1)}}$
% has been calculated.
}
\label{fig:RDBRbatch}
\end{figure}
 
 
%  \begin{equation}
%   c_1(x)=(c_1^1(x),c_1^2(x),...,c_1^l(x))
%  \end{equation}
 
 \begin{figure}
\centering
$
\psmatrix[colsep=.6cm,rowsep=.4cm,linewidth=.4pt]
&\bigcirc&\|&\bigcirc\\
\\
&\bigcirc&\|&\bigcirc\\
\enspace&\enspace&\enspace&\enspace&\enspace\\
\\
&\bigcirc&\|&\bigcirc\\
\\
&\bigcirc&\|&\bigcirc\\
\ncline{->}{1,2}{3,4}
\ncline{->}{3,2}{1,4}
\ncline[linestyle=dotted]{1,2}{1,3}
\ncline[linestyle=dotted]{3,2}{3,3}
\nccircle[linestyle=none]{1,2}{.1cm}^{ y_i^{\mathrm{(\tau)}} }
\nccircle[linestyle=none]{1,4}{.1cm}^{ y_i^{\mathrm{(\tau+1)}} }
\nccircle[linestyle=none]{3,2}{.1cm}^{ y_j^{\mathrm{(\tau)}} }
\nccircle[linestyle=none]{3,4}{.1cm}^{ y_j^{\mathrm{(\tau+1)}} }
\ncline{4,1}{4,5}
\ncline{->}{6,2}{8,4}
\ncline{->}{8,4}{6,4}
\ncline[linestyle=dotted]{6,2}{6,3}
\ncline[linestyle=dotted]{8,2}{8,3}
\nccircle[linestyle=none]{6,2}{.05cm}^{ y_i^{\mathrm{(\tau)}} }
\nccircle[linestyle=none]{6,4}{.05cm}^{ y_i^{\mathrm{(\tau+1)}} }
\nccircle[linestyle=none]{8,2}{.1cm}^{ y_j^{\mathrm{(\tau)}} }
\nccircle[linestyle=none]{8,4}{.1cm}^{ y_j^{\mathrm{(\tau+1)}} }
\endpsmatrix
$
\caption{Estrutura do RDBR com atualização estática (imagem acima) 
e dinâmica (imagem abaixo) dos rótulos.
Na atualização dinâmica, a estimativa dos rótulos $\hat{y_{i}}^{\mathrm{(\tau+1)}}$
é baseado nas estimativas dos rótulos anteriores (da iteração $\mathrm{(\tau)}$)
e nas da iteração atual ($\mathrm{(\tau+1)}$), se
disponíveis.
% 
% 
% Basic idea of the recursive dependent binary relevance
% classifier (RDBR), stochastic version.
% In the upper part the update strategy of the batch version is shown.
% A label $\hat{y_{i}}^{\mathrm{(\tau+1)}}$ is estimated,
% based exclusively on the label
% estimates of the previous estimates $\hat{y_{j}}^{\mathrm{(\tau)}}$.
% In the lower part the update strategy of the stochastic version is shown.
% A label $\hat{y_{i}}^{\mathrm{(\tau+1)}}$ is estimated,
% based on the label estimates of the previous estimates
% and on the current estimates $\hat{y_{j}}^{\mathrm{(\tau+1)}}$,
% as soon as they become available.
}
\label{fig:RDBRstochastic}
\end{figure}

 Assim que $c_1$ classifica a instância $(x,\hat{y}^0)$, gerando portanto a estimativa de rótulos $\hat{y}^1=c_1(x,\hat{y}^0)$,
 $\hat{y}^1$ é usado para atualizar as características da instância $x$, tomando assim o lugar de $\hat{y}^0$.
 Esse processo de atualização das características é iterativo e é repetido $k$ vezes,
 onde $k$ é determinado por um valor máximo de iterações, definido a priori, ou quando é detectado a convergência.
 A convergência é alcançada quando a estimativa de rótulos não muda, independente do número de iterações.
%  Isso acontece, por exemplo, quando $c_1(c_1(c_0))=c_1(c_0)$.
 Com $k$ iterações, tem-se $k$ estimativas de rótulos $\hat{y}^1,\hat{y}^2,...,\hat{y}^k$, dentre as quais o último ($\hat{y}^k$)
 é a classificação final do método $C(x)=\hat{y}^k$.
 
 Dessa forma, podemos concluir que \MRLM~é um método recursivo de tal forma que
 para $k=1$, $C(x)=c_1(x,c_0(x))$,
 para $k=2$, $C(x)=c_1(x,c_1(x,c_0(x)))$,
 para $k=3$, $C(x)=c_1(x,c_1(x,c_1(x,c_0(x))))$ e assim por diante.
 Note que para $k=0$, o \MRLMa~é exatamente o BR, $C(x)=c_0(x)$.
%  a aplicação de $c_1$ $3$ vezes sobre
%  $c_0(x)$ resulta na estimativa $\hat{y}^3=c_1(c_1(c_1(c_0(x))))$ e assim por diante.
 Aplicando esse processo recursivo, espera-se que a cada recursão $i$ a estimativa dos rótulos $\hat{y}^i$ seja melhor do que
 seu antecessor $\hat{y}^{i-1}$. Teoricamente, essa afirmação se mantém se supormos que a estimativa $\hat{y}^1$ é melhor do que a $\hat{y}^0$, 
 o que é razoável uma vez que o classificador $c_0$, que é um BR, obtêm seu resultado usando apenas estimativas marginais dos rótulos,
 %  ($P(y|x)=\prod_{j=1}^l{P(y_j,x)}$)
  enquanto que $c_1$ explora a correlação dos rótulos ao usá-los como características, obtendo assim 
 estimativas baseadas na probabilidade condicional.
 Com essa suposição teríamos que $\hat{y}^i$ seria melhor do que $\hat{y}^{i-1}$, pois $\hat{y}^{i-1}$ se aproxima
 mais da distribuição real dos rótulos do que $\hat{y}^{i-2}$. Assim, quando $c_1$ estimar $\hat{y}^i$ usando $\hat{y}^{i-1}$ estaria baseado em 
 uma distribuição mais próxima daquela em que foi treinado do que usando $\hat{y}^{i-2}$.
 Lembrando que $c_1$ foi treinado usando apenas rótulos assumidamente corretos.
  Olhando por todo o procedimento descrito, o \MRLMa~pode ser simplesmente visto como uma generalização do BR e do DBR
 que insere uma inteligência
 adicional a aplicação e uso do classificador $c_1$ de DBR, afim de que ele seja melhor aproveitado.
 A figura \ref{fig:RDBRbatch} ilustra bem o funcionamento do RDBR.
 Nela vemos quais estimativas de rótulos são utilizadas como características adicionais
 para próxima estimativa de rótulos.
 
  Adicionalmente, o \MRLMa~adota uma técnica extra, inspirada no Classifier Chain que consiste em, para
 cada classificador binário $c_1^j$, atualizar a característica $\hat{y}_j$ imediatamente após 
 a sua classificação. Dessa forma, os classificadores binários seguintes, $c_1^{j+1},c_1^{j+2},...,c_1^{r}$,
 classificarão suas instâncias baseados em estimativas de rótulos mais atuais, possivelmente melhores.
 Isso é ilustrado na figura \ref{fig:RDBRstochastic} e é chamado de atualização dinâmica dos rótulos.
 

 
 \section{Análise}
 \label{sec:mrlm_analise} 
 
 Nessa seção o método \MRLMa~é posto em prova. Com objetivo de analisar o método, implementou-se o algoritmo
 usando a linguagem de programação Java e no \textit{Weka} \cite{weka},
 que é uma biblioteca que integra técnicas de reconhecimento de padrões.
 A principal hipótese em que o \MRLMa~é baseado será testado nessa seção com o intuito de validar o método.
 Com a finalidade de tornar os testes mais objetivos, a hipótese é melhor formalizado assim:
 \begin{itemize}

  \item Dados uma métrica $M$, uma base de Teste $D=\{x_1,x_2,...,x_n\}$,
  um DBR induzido composto pelos classificadores multirrótulos $c_0$ e $c_1$ e
  dois vetores de predições de $r$ rótulos:
  \begin{equation}
  \begin{split}
  & p=(p_1,p_2,...,p_n) : p_i \in {\{0,1\}}^r |1 \leq i \leq n \\
  & b=(b_1,b_2,...,b_n) : b_i \in {\{0,1\}}^r |1 \leq i \leq n
  \end{split}
  \end{equation}
  tal que $M(p_2) \geq M(p_1)$,
  então:
  \begin{equation}
  M((c_1(x_i,p_1) | 1 \leq i \leq n)) \leq M((c_1(x_i,p_2) | 1 \leq i \leq n))
  \end{equation}
 
 \end{itemize}

Resumidamente, a hipótese é que erros de predições pelo
classificador $c_0$ do DBR afetam negativamente a classificação do classificador $c_1$.
A comprovação dessa hipótese é feita da seguinte forma. Experimentos com o \MRLMa~são realizados
usando 7 bases de dados de domínio públicos. Cada experimento consiste em medir o valor da métrica
\SA~quando o método é submetido a validação cruzada de 10 \textit{folds}.
O experimento é repetido com o número máximo de iterações do
\MRLMa~variando de 0 a 10 (Note que para o valor 0, o \MRLMa~se torna exatamente o BR).
Ao variar esse parâmetro, espera-se que o método obtenha desempenho melhor para os valores mais altos.
De fato, é o que ocorre na maioria dos casos, apesar de que o método converge rapidamente em relação ao
número de iterações.
Os gráficos da figura \ref{fig:mrlmgraph1} mostram o que ocorre em 5 dos 7 casos testados: o método tem seu desempenho melhorado
até o valor máximo de iterações chegar a 2, depois disso o método não tem seu desempenho alterado.
Portanto 2 foi o valor máximo de iterações necessárias para o método convergir nesses casos.
Nos outros dois casos o método convergiu com apenas uma iteração ou piorou 
com duas ou mais iterações. Veja os dois gráficos dos dois casos na figura \ref{fig:mrlmgraph2}.
Vale ressaltar que em 6 dos 7 casos, 
o método \MRLMa~conseguiu um desempenho melhor do que o DBR e em apenas um dos casos
alcançou o mesmo desempenho do DBR.



\begin{figure}
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[angle=-90, width=1\linewidth]{plots/emotions.pdf}
  \caption{Emotions}
  \label{fig:subemotions}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[angle=-90, width=1\linewidth]{plots/medical.pdf}
  \caption{Medical}
  \label{fig:submedical}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[angle=-90, width=1\linewidth]{plots/scene.pdf}
  \caption{Scene}
  \label{fig:subscene}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[angle=-90, width=1\linewidth]{plots/enron.pdf}
  \caption{Enron}
  \label{fig:subenron}
\end{subfigure}

\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[angle=-90, width=1\linewidth]{plots/yeast.pdf}
  \caption{Yeast}
  \label{fig:subyeast}
\end{subfigure}
\caption{Gráficos de análise de desempenho do \MRLMa.}
\label{fig:mrlmgraph1}
\end{figure}

\begin{figure}
\centering
 \begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[angle=-90, width=1\linewidth]{plots/birds.pdf}
  \caption{Birds}
  \label{fig:subbirds}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[angle=-90, width=1\linewidth]{plots/genbase.pdf}
  \caption{Genbase}
  \label{fig:subgenbase}
\end{subfigure}

\caption{Gráficos de análise de desempenho do \MRLMa~nos dois experimentos em que
o \MRLMa~não melhorou na sua segunda iteração.}
\label{fig:mrlmgraph2}
\end{figure}

\FloatBarrier


É importante analisar o quanto o método aumenta o tamanho da base de dados uma vez que isso acarreta no aumento
do tempo de execução do algoritmo. Seja $r$ o número de rótulos, $n$ o número de instâncias de treino
e $m$ o número de atributos da base original, na fase de treinamento do \MRLMa, o número de base de dados utilizadas são
$2r$, cada uma contendo $n$ instâncias. Em metade delas, as instâncias contidas tem $m$ atributos e na outra metade $m+r$ atributos.
Já na fase de predição do algoritmo, no pior caso, o algoritmo usa $(k+1)r$ bases de dados de $n$ instâncias onde na primeira base, o
número de atributos é igual a $m$ e nas restantes é igual $m+r$. Vale ressaltar que nem todas essas bases de dados precisam ser
armazenados explicitamente na mémoria em espaços diferentes, algumas são reutilizadas no processo de predição.

% Em relação a complexidade algorítma do \MRLMa, ela pode ser
% aproximada pelo número de atributos destinados ao classificador base, uma vez que é um método de transformação
% e a maior parte do custo computacional se encontra no classificador base.
% A complexidade 




\chapter{Avaliação e Análise Experimental}
Neste capítulo é descrito as bases de dados multirrótulo usadas nos experimentos, 
as medidas de avaliação escolhidas e a escolha
dos parâmetros dos classificadores. 
A comparação e estudo dos métodos é feita considerando a qualidade de predição.
A qualidade de predição é estimada pelo método de avaliação
por validação cruzada com 10 grupos (\textit{10-fold cross-validation}), descrito na seção \ref{sec:modelav},
sobre \Nbases~bases de dados, todas apresentadas e descritas na subseção \ref{sec:datas}.

Para quantificar a qualidade de predição, 3 métricas foram utilizadas.
As métricas escolhidas, bem como o motivo das escolhas,
são listadas:
\begin{itemize}
 \item Subset Accuracy, pois é mostrado que captura bem se o método explora a correlação entre rótulos;
 \item Hamming Loss, pois é bem mais sensível que o Subset Accuracy;
 \item Example Based Accuracy, é o meio termo entre o Hamming Loss e o Subset Accuracy.
%  \item Tempo computacional, pois é @@@ etc...
\end{itemize}

As fórmulas para o cálculo de cada uma das métricas são apresentadas na seção \ref{sec:metrics}.
É interessante mostrar os resultados experimentais usando diferentes métricas, pois cada uma captura
um aspecto diferente da classificação. 

Os experimentos foram realizados utilizando \Nml~modelos de classificação multirrótulo: BR, DBR, RDBR, CC, ECC e MCC.
Os classificadores bases usados, aqueles que são utilizados como classificadores binários para
cada um dos métodos multirrótulos citados, foram os seguintes:
KNN, SVM, \jqo~e Regressão Logística.
Implementações públicas dos classificadores na biblioteca \textit{Weka} \cite{weka} foram usados para este trabalho.
A seguir a descrição de cada um dos classificadores binários.

\begin{itemize}
 \item \textbf{KNN}: O KNN é uma das técnicas do aprendizado supervisionado mais conhecida. 
 O KNN funciona da seguinte forma: Uma instância de características $x',x'\in X$
 e de classe desconhecida é classificado baseado
 nas classes dos $K$ vizinhos mais próximos, onde mais próximo entende-se por aquela instância
 $(x,y)$, para $x \in X$ e $y \in Y$,
 cuja distância euclidiana entre os vetores reais $x$ e $x'$ é mínima. 
 A classe predominante dos $K$ vizinhos mais próximos será a classe atribuída para $x'$ \cite{topalgos2008}.
 
 \item \textbf{SVM}: 
 Em um problema de classificação binária, o objetivo do SVM é encontrar o melhor hiperplano, 
 definida pela função de hiperplano $h(x)=0$ para $x \in X$,
 que separa as duas classes na base de treino.
 O ``melhor'' hiperplano é definido como aquele que simultaneamente minimiza
 o erro de classificação e maximiza a distância do hiperplano à instância mais próxima dele \cite{topalgos2008}. 
 
 \item \textbf{\jqo}: 
 O \jqo~é um algoritmo para contruir uma árvore de decisão.
 Segundo \cite{peng2009implementation} uma árvore de decisão é uma
 árvore cujos nós folhas representam decisões e os nós não-folhas representam
 uma escolha entre alternativas. Cada nó não-folha é associado a um atributo da base e
 cada ligação desse nó a seus nós filhos está associado a um valor possível desse atributo.
 Cada nó folha é associado a uma classe.
 Quando uma instância de teste é submetida ao classificador, o algoritmo começa nó raiz e caminha
 em direção ao nó filho cuja ligação está associado ao mesmo valor do atributo que a instância de teste tem.
 O algoritmo continua nesse mesmo processo, caminhando sobre os nós e ligações até chegar a um nó folha, onde então
 a instância de teste é classificado com a classe associada ao nó folha.
 A quantidade de nós e as associações dos nós as seus respectivos atributos,valores de atributos ou classes
 são feitas pelo algoritmo
 de construção da árvore, que nesse trabalho utilizamos o \jqo.

 \item \textbf{Regressão Logística}
 Segundo \cite{james2013introduction} o classificador baseado na Regressão Logística 
 é um modelo probabilístico da estatística. Num problema de classificação binária,
 esse classificador usa um modelo de regressão não-linear
 para calcular a probabilidade de um instância qualquer pertencer a classe positiva.
 O modelo de regressão não-linear usado é a função logística, 
 \begin{equation} \label{eq:RL}
  p(\yy=1|\xx) = \frac{e^{\ww \cdot \xx}}{1+e^{\ww \cdot \xx}}
 \end{equation}
onde $\xx$ é o vetor de características, $\yy$ é a classe positiva e $\ww$ é um vetor de coeficientes de mesma dimensão
que $\xx$ o qual é estimado durante a fase de treinamento do algoritmo pela máxima verossimilhança \cite{james2013introduction}.
Pela equação \ref{eq:RL} podemos calcular a probabilidade de uma instância de características $\xx$ pertencer a classe $\yy$.
\end{itemize}


A análise experimental dos métodos se encontram divididos em dois estudos. O primeiro estudo consiste em
comparar os métodos quando todos usam um mesmo classificador base em específico
e o segundo em comparar cada combinação de um
modelo de classificação multirrótulo com um classificador base. 
Ambos estudos são detalhados na seção \ref{sec:exps}.



% Para o melhor entendimento, neste capítulo um método multirrótulo é definido como sendo a combinação
% de um modelo de classificação multirrótulo com uma configuração de parâmetros pré-definida. Assim, por exemplo,
% o classificador BR com KNN é considerado um método diferente do classificador BR com SVM.
% Isso, por um lado é bom
% pois testa o desempenho dos classificadores multirrótulo quando não é gasto tempo computacional para ajustar parâmetros.
% Por outro lado é ruim uma vez que considera os mesmos modelos de classificação como sendo completamente diferentes.
% Dessa forma, foram considerados 24 métodos multirrótulos e comparados entre si de forma experimental.


\section{Base de dados}
\label{sec:datas}
As bases de dados são apresentadas na tabela \ref{tab:datas}.
Sete das oito bases de dados utilizadas nos experimentos foram obtidas do repositório público
de endereço virtual http://mulan.sourceforge.net/datasets.html.
A única base de dados não obtida pelo repositório público acima é a nomeada Motorpump, que é uma
base de dados privada \cite{mendel2008}.



% Yeast:
%  Emotions: 
%  Medical:
%  Eron: Pertencente ao domínio de bases de dados do tipo texto a eron possui um
% número de 1702 instanciam relacionadas com 53 rótulos e 1001 atributos discretos.
% 
% 
% 
% \begin{itemize}
% \item \bf{Birds}: ??
% 
% \item \bf{Emotions}: A base de dados emoctions (Wieczorkowska, Synak, and Rás 2006 apud
% Santos, 2012 apud SÁ, 2008) está relacionada com a classificação de músicas de
% acordo com as emoções, esta base possui um número de 593 instancias associadas a
% um subconjunto de 6 rótulos. Cada instância possui 72 atributos numéricos e 0
% atributos discretos.
% \item \bf{Enron}: ??
% 
% \item \bf{Genbase}: ??
% 
% \item \bf{Medical}:  A base de dados Medical é composta de documentos com um resumo de
% texto livre de histórias de sintomas e prognóstico que são usados para prever códigos
% seguros e está disponível no site
% http://www.computationalmedicine.org/challenge/index.php. Esta base de dados
% contém 978 instâncias, descritas por 1449 atributos discretos, com possibilidade de
% associação a 45 rótulos (classes).
% 
% \item \bf{Motorpump}: ??
% 
% \item \bf{Scene}: ??
% 
% \item \bf{Yeast}: a base de dados biológicos yeast (Clare and king 2001 apud SÁ, 2008) esta
% relacionada a classificação de funções de proteínas. Está base contém microvetores de
% expressões e perfis filogenéticos de 2417 instancias (exemplos). Onde cada instancia
% está associada a um subconjunto de 14 categorias (rótulos) possíveis do nível mais
% acima do catálogo funcional (FunCat). Cada instância apresenta 103 atributos
% numéricos (NUM) e 0 atributos discretos (DIS).
% 
% \end{itemize}

\begin{table}[h]
\begin{tabular}{|l|ccccccc|}
\hline
% \textbf{}         & \textbf{}        & \textbf{}         & \multicolumn{2}{c}{\textbf{ATRIBUTOS}} & \textbf{}        & \textbf{}              & \textbf{}          \\
\textbf{BASE}      & \textbf{DOM} & \textbf{EXEMPLOS} & \textbf{DIS} & \textbf{NUM} & \textbf{RÓTULOS} & \textbf{CARD} & \textbf{DENS} \\ \hline
\textbf{Birds}     & Audio            & 645               & 2                 & 258                & 19               & 1.014                  & 0.053              \\
\textbf{Emotions}  & Música           & 593               & 0                 & 72                 & 6                & 1.869                  & 0.311              \\
\textbf{Enron}     & Texto            & 1702              & 1001              & 0                  & 53               & 3.378                  & 0.064              \\
\textbf{Genbase}   & Biologia         & 662               & 1186              & 0                  & 27               & 1.252                  & 0.046              \\
\textbf{Medical}   & Texto            & 978               & 1449              & 0                  & 45               & 1.245                  & 0.028              \\
\textbf{Motorpump} & Vibração         & 1372              & 0                 & 40                 & 9                & 2.249                  & 0.250              \\
\textbf{Scene}     & Imagem           & 2407              & 0                 & 294                & 6                & 1.074                  & 0.179              \\
\textbf{Yeast}     & Biologia         & 2417              & 0                 & 103                & 14               & 4.237                  & 0.303              \\  \hline

\end{tabular}
\caption{Resumo das bases de dados multirrótulos}
\label{tab:datas}
\end{table}

A tabela \ref{tab:datas} apresenta algumas estatísticas das bases de dados adquiridas.
Nela são apresentadas as seguintes informações de cada base de dados:
\begin{itemize}
  \item \textbf{DOM}: Domínio pertencente;
  \item \textbf{DIS}: Número de atributos discretos;
  \item \textbf{NUM}: Número de atributos numéricos;
  \item \textbf{CARD}: Cardinalidade de rótulos na base de dados, que significa o número médio de rótulos por exemplo;
  \item \textbf{DENS}: Densidade de rótulos na base de dados. Calculado pela divisão da cardinalidade pelo número de possíveis rótulos.
\end{itemize}


% \section{Método de Comparação}
% \label{sec:methodcomp}


% 
% Este capítulo se encontra dividido em duas seções, na primeira foram analisados os
% resultados dos métodos de transformação para cada classificador base.
% Já na segunda seção cada combinação de método multirrótulo com classificador base foi considerado
% um método de transformação e seus resultados são comparados entre si juntamente com os métodos multirrótulos
% de adaptação.


\section{Resultados Experimentais}
\label{sec:exps}
Nesta seção é feita uma análise do desempenho dos métodos multirrótulos em cada uma das bases de dados
em diferentes métricas.
A análise experimental dos métodos se encontram divididos em dois estudos.
O primeiro estudo consiste em
comparar os métodos quando todos usam um mesmo classificador base em específico
e o segundo em comparar cada combinação de um
modelo de classificação multirrótulo com um classificador base. 
No primeiro estudo, que chamaremos de Estudo Específico, para cada um dos 4 classificadores bases, 
cada método multirrótulo é 
testado e enumerado de 1 a 6 segundo a ordem de melhor desempenho.
O método que obtiver o melhor desempenho, lhe é atribuído o valor 1,
o segundo melhor, lhe atribuído 2 e assim por diante.
Essa enumeração é chamada de \textit{ranking} e o valor atribuído de \textit{rank}.
No segundo estudo,
que chamaremos de Estudo Geral,
o \textit{rank} de cada método varia de 1 a 24, 
uma vez que cada
combinação de um modelo de classificação multirrótulo com um classificador base
é considerado um método novo.
Note que no Estudo Geral
o \textit{rank} de um método multirrótulo que tem como o classificador base, por exemplo o KNN,
é afetado pelo desempenho do mesmo método porém com outro classificador base.
O Estudo Específico
tem por principal objetivo evitar que isso aconteça.
Adicionalmente, o Estudo Específico tem por objetivo
analisar se cada método multirrótulo
apresenta desempenhos diferentes para
diferentes classificadores, ou seja, se o \textit{ranking} é alterado ao alterar o classificador base.
O Estudo Geral
tem por objetivo analisar as possíveis combinações de classificadores bases e modelo de classificação multirrótulo
sem tornar a comparação e o \textit{ranking} específicos
para um subconjunto dessas possíveis combinações.
O motivo disso é tomar um ponto de vista em que se desconhece
o classificador base que melhor se adapta a cada base a priori.
Essa seção é dividida em 2 subseções, um para o Estudo específico e
outro para o Estudo Geral, ambos definidos no ínicio do capítulo.

No Estudo Específico os métodos tiveram seus classificadores bases fixados.
% A razão disso vem do fato de que queremos comparar os métodos multirrótulos entre si,
% e não os seus classificadores bases.
Ao fixarmos o classificador base, 
o desempenho irá depender apenas do modelo de classificação multirrótulo
de cada um.
Em cada subseção e para cada métrica escolhida é apresentado uma tabela
contendo os valores da métrica para cada um dos métodos multirrótulo e
o ranking dos métodos multirrótulos.



\subsection{Estudo Específico}
\input{tabelas2/ESknn.tex}
\input{tabelas2/ESsvm.tex}
\input{tabelas2/ESj48.tex}
\input{tabelas2/ESlogi.tex}



Vejamos alguns pontos interessantes nos testes das tabelas
\ref{tab:ESknn}, onde o KNN foi utilizado.
Note que o \textit{ranking} dos métodos mudou bastante de métrica para métrica.
No caso do BR, o ranking médio caiu de $4.5$ no \SA~para $1.75$ no \HL, ou seja,
de penúltimo colocado no ranking médio para o primeiro colocado. 
Isso não só ocorre com o KNN, mas também para os outros classificadores bases, cujos resultados
se encontram nas tabelas
\ref{tab:ESsvm}, \ref{tab:ESj48} e \ref{tab:ESlogi}.
% \ref{tab:SAsvm},\ref{tab:HLsvm},\ref{tab:EBAsvm},
% \ref{tab:SAj48},\ref{tab:HLj48},\ref{tab:EBAj48},
% \ref{tab:SAlogi},\ref{tab:HLlogi} e \ref{tab:EBAlogi}.
Note que em todas as tabelas, para a base de dados \textit{Enron},
o valor do \SA~é o mais baixo dentre todas as bases.
Isso é esperado uma vez que é a base com maior número de rótulos ($53$) e o
\SA~exige fortemente que a predição do classificador acerte a única possível combinação dentre as $2^{53}$ possíveis.
Mas o interessante é que, apesar do \SA~ser o pior para essa base, o \HL~é o quarto melhor.
Isso sugere que há alguns poucos rótulos que são difíceis de serem corretamente preditos.
Para o classificador base KNN, o RDBR obteve o melhor resultado na métrica \SA~e na métrica \EBA.

A ordem dos métodos que obtiverem o melhor rank médio altera-se consideravelmente
ao alterar o classificador base.
Por exemplo, com o KNN, a ordem crescente do rank médio no \SA~é \MRLMa,MCC,DBR,CC,BR,ECC,
entretanto com o SVM a ordem mudou para ECC,MCC,\MRLMa,CC,DBR,BR.

O método BR alcança resultados melhores pela métrica \HL~do que para as outras.
O seu ranking médio é sempre menor quando medido pelo \HL. Isso sugere que, apesar
do BR não capturar a dependência entre rótulos, ele captura bem a dependência
que cada rótulo tem com o vetor de características. Uma hipótese para explicar
o desempenho dos métodos multirrótulos que exploram correlação entre rótulos ser
pior que o do BR em alguns casos, é que os métodos empenham muitos esforços para 
achar a dependência entre os rótulos e acabam desprezando a dependência de cada
rótulo com o vetor de características. 
Por exemplo, se o problema multirrótulo tiver um número de rótulos relativamente muito maior 
que o número de características, a estratégia de expandir o espaço de características com 
os valores dos rótulos irá reduzir significativamente a importância do vetor de características.
A hipótese é verdadeira quando não há (ou é baixa) a correlação entre rótulos
na base de dados ou quando é complexa demais para ser entendida pelos métodos atuais.

% Note mais uma vez que o desempenho muda muito de métrica pra métrica. O \CC~que tem
% o segundo melhor \textit{ranking} médio no \SA, tem o pior \textit{ranking} médio no
% Hamming Loss.


\FloatBarrier
\subsection{Estudo Geral}

As tabelas \ref{tab:allresultsSA},\ref{tab:allresultsHL} e \ref{tab:allresultsEBA} mostram o  resultado alcançado
por cada combinação de modelo de classificação multirrótulo e classificador base nas métricas \SA,\HL~e \EBA.
O ECC com KNN foi o único que não alcançou nenhum resultado, pois precisou de mais memória principal do que
tinha disponível e é por isso que temos nas tabelas o símbolo do ponto de interrogação em seu resultado.
A esse atribuímos a última colocação na base correpondente.
Observando as tabelas podemos notar
que os método multirrótulo ECC obtém os melhores resultados em geral. O ECC com \jqo~obteve o 
melhor rank médio para as métricas \SA~e \HL, e o segundo melhor rank médio para a métrica \EBA.
O \MRLMa~com KNN alcançou resultados bons, ele teve o segundo melhor rank médio pela métrica \SA.
Interessante que o \MRLMa~com KNN obtém resultados muito melhores do que com outros classificadores base.
Isso não ocorre com outros métodos, visto que alguns alcançam resultados melhores usando SVM e outros com \jqo.
Note que o \textit{rank} de cada um dos métodos variam muito de base de dados para base de dados, ou seja, desvio padrão
dos \textit{rank} é alto. Por exemplo, o MCC com KNN alcançou o pior desempenho na base \textit{Enron}, porém 
teve o melhor desempenho na \textit{Yeast}. Esse desvio padrão alto sugere que não há método multirrótulo 
com um classificador base único que
seja bom para todos os problemas, cada um é bom para um tipo de problema.

\input{tabelas/SAall.tex}
\input{tabelas/HLall.tex}
\input{tabelas/EBAall.tex}

\FloatBarrier



\chapter{Conclusão}
\label{sec:conclusions}

Este trabalho teve por objetivo as seguintes atividades:
\begin{enumerate}
 \item Descobrir como medir e explorar correlação entre rótulos;
 \item Análise crítica dos métodos multirrótulos;
 \item Elaboração de um algoritmo de um novo método multirrótulo;
\end{enumerate}
O objetivo 1 foi considerado alcançado ao verificarmos que a métrica \SA~mede a 
exploração da correlação entre rótulos e também ao verificarmos que a estratégia adotada por vários 
métodos que se baseia na expansão do espaço de características com valores de rótulos, realmente
faz com que o modelo de classificação considera dependência entre rótulos, mesmo que parcialmente.
O objetivo 2 foi considerado alcançado pelas análises feita na seção \ref{sec:exps}.
O objetivo 3 foi considerado alcançado, pois desenvolveu-se um novo modelo de classificação,
chamado de \MRLM, que apresenta resultados melhores que alguns métodos multirrótulo da literatura.
Vale ressaltar que o novo método apresentou sempre resultados experimentais melhores que o método na qual
ele foi baseado, o DBR. Isso comprova que o novo método é uma melhoria do antigo.

Adicionalmente, a partir dos experimentos mostrados e analisados na seção \ref{sec:exps} podemos
chegar aos seguintes pontos conclusivos:
  \begin{itemize}
   \item o melhor classificador base para um método multirrótulo, aquele que resulta no maior desempenho em uma métrica,
   não é necessariamente o melhor para os outros métodos multirrótulos. 
   \item Para problemas multirrótulo cuja dependência entre rótulos é baixa, inexistente ou complexa, o
   método \BR~apresenta resultados melhores que os métodos multirrótulo estudados.
   \item A métrica \SA~tende a ser alto para métodos que exploram correlação entre rótulos, e o contrário
   para o \HL.
  \end{itemize}


  
